{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import copy \n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl \n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    device = torch.device(\"cuda\")\n",
    "    MAX_SEQ = 100\n",
    "    EMBED_DIMS = 512\n",
    "    ENC_HEADS = DEC_HEADS = 8\n",
    "    NUM_ENCODER = NUM_DECODER = 4\n",
    "    BATCH_SIZE = 32\n",
    "    TRAIN_FILE = \"../data/train_data_ws_v3.csv\"\n",
    "    TEST_FILE = \"\"\n",
    "    TOTAL_EXE = 13523\n",
    "    TOTAL_CAT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DKTDataset(Dataset):\n",
    "    def __init__(self, samples, max_seq):\n",
    "        super().__init__()\n",
    "        self.samples = samples\n",
    "        self.max_seq = max_seq\n",
    "        self.data = []\n",
    "        for id in self.samples.index:\n",
    "            te_ids, qu_ids, cat, lag, ans = self.samples[id]\n",
    "            if len(qu_ids) > max_seq:\n",
    "                for l in range((len(qu_ids)+max_seq-1)//max_seq):\n",
    "                    self.data.append(\n",
    "                        (qu_ids[l:l+max_seq], ans[l:l+max_seq], lag[l:l+max_seq], cat[l:l+max_seq]))\n",
    "            elif len(qu_ids) < self.max_seq and len(qu_ids) > 50:\n",
    "                self.data.append((qu_ids, ans, lag, cat))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        test_ids, question_ids, tags, lag_time, answers = self.data[idx]\n",
    "        seq_len = len(test_ids)\n",
    "\n",
    "        te_ids = np.zeros(self.max_seq, dtype=int)\n",
    "        qu_ids = np.zeros(self.max_seq, dtype=int)\n",
    "        cat = np.zeros(self.max_seq, dtype=int)\n",
    "        lag = np.zeros(self.max_seq, dtype=int)\n",
    "        ans = np.zeros(self.max_seq, dtype=int)\n",
    "        if seq_len < self.max_seq:\n",
    "            te_ids[-seq_len:] = test_ids\n",
    "            qu_ids[-seq_len:] = question_ids\n",
    "            cat[-seq_len:] = tags\n",
    "            lag[-seq_len:] = lag_time\n",
    "            ans[-seq_len:] = answers\n",
    "\n",
    "        else:\n",
    "            te_ids[:] = test_ids[-self.max_seq:]\n",
    "            qu_ids[:] = question_ids[-self.max_seq:]\n",
    "            cat[:] = tags[-self.max_seq:]\n",
    "            lag[:] = lag_time[-self.max_seq:]\n",
    "            ans[:] = answers[-self.max_seq:]\n",
    "\n",
    "        input_rtime = np.zeros(self.max_seq, dtype=int)\n",
    "        input_rtime = np.insert(lag_time, 0, 0)\n",
    "        input_rtime = np.delete(input_rtime, -1)\n",
    "\n",
    "        input = {\"input_ids\": qu_ids, \"input_rtime\": input_rtime.astype(\n",
    "            np.int), \"input_cat\": cat}\n",
    "        return input, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders():\n",
    "    dtypes = {\"uid\": \"int64\", \"question_id\": \"int64\",\n",
    "              \"test_id\": \"int64\", \"answer\": \"int8\", \"timestamp\": \"int64\",\n",
    "              \"tag\": \"int64\", \"question_lag_time\": \"float64\"}\n",
    "    print(\"loading csv.....\")\n",
    "    train_df = pd.read_csv(Config.TRAIN_FILE, usecols=[\n",
    "                           0, 1, 2, 3, 4, 5, 7], dtype=dtypes, )\n",
    "    print(\"shape of dataframe :\", train_df.shape)\n",
    "\n",
    "    train_df = train_df.sort_values(\n",
    "        [\"timestamp\"], ascending=True).reset_index(drop=True)\n",
    "    n_skills = train_df.question_id.nunique()\n",
    "    print(\"no. of skills :\", n_skills)\n",
    "    print(\"shape after exlusion:\", train_df.shape)\n",
    "\n",
    "    # grouping based on user_id to get the data supplu\n",
    "    print(\"Grouping users...\")\n",
    "    group = train_df[[\"uid\", \"question_id\", \"test_id\", \"answer\", \"tag\", \"question_lag_time\"]]\\\n",
    "        .groupby(\"uid\")\\\n",
    "        .apply(lambda r: (r.test_id.values, r.question_id.values,\n",
    "                          r.tag.values, r.question_lag_time.values, r.answer.values))\n",
    "    del train_df\n",
    "    gc.collect()\n",
    "    print(\"splitting\")\n",
    "    train, val = train_test_split(group, test_size=0.2)\n",
    "    print(\"train size: \", train.shape, \"validation size: \", val.shape)\n",
    "    train_dataset = DKTDataset(train, max_seq=Config.MAX_SEQ)\n",
    "    val_dataset = DKTDataset(val, max_seq=Config.MAX_SEQ)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=Config.BATCH_SIZE,\n",
    "                              num_workers=8,\n",
    "                              shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset,\n",
    "                            batch_size=Config.BATCH_SIZE,\n",
    "                            num_workers=8,\n",
    "                            shuffle=False)\n",
    "    del train_dataset, val_dataset\n",
    "    gc.collect()\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading csv.....\n",
      "shape of dataframe : (2266586, 7)\n",
      "no. of skills : 9454\n",
      "shape after exlusion: (2266586, 7)\n",
      "Grouping users...\n",
      "splitting\n",
      "train size:  (5358,) validation size:  (1340,)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, in_feat):\n",
    "        super(FFN, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_feat, in_feat)\n",
    "        self.linear2 = nn.Linear(in_feat, in_feat)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.linear1(x))\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class EncoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_exercises, n_categories, n_dims, seq_len):\n",
    "        super(EncoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.exercise_embed = nn.Embedding(n_exercises, n_dims)\n",
    "        self.category_embed = nn.Embedding(n_categories, n_dims)\n",
    "        self.position_embed = nn.Embedding(seq_len, n_dims)\n",
    "\n",
    "    def forward(self, exercises, categories):\n",
    "        e = self.exercise_embed(exercises)\n",
    "        c = self.category_embed(categories)\n",
    "        seq = torch.arange(self.seq_len, device=Config.device).unsqueeze(0)\n",
    "        p = self.position_embed(seq)\n",
    "        return p + c + e\n",
    "\n",
    "\n",
    "class DecoderEmbedding(nn.Module):\n",
    "    def __init__(self, n_responses, n_dims, seq_len):\n",
    "        super(DecoderEmbedding, self).__init__()\n",
    "        self.n_dims = n_dims\n",
    "        self.seq_len = seq_len\n",
    "        self.response_embed = nn.Embedding(n_responses, n_dims)\n",
    "        self.time_embed = nn.Linear(1, n_dims, bias=False)\n",
    "        self.position_embed = nn.Embedding(seq_len, n_dims)\n",
    "\n",
    "    def forward(self, responses):\n",
    "        e = self.response_embed(responses)\n",
    "        seq = torch.arange(self.seq_len, device=Config.device).unsqueeze(0)\n",
    "        p = self.position_embed(seq)\n",
    "        return p + e\n",
    "\n",
    "\n",
    "class StackedNMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_stacks, n_dims, n_heads, seq_len, n_multihead=1, dropout=0.0):\n",
    "        super(StackedNMultiHeadAttention, self).__init__()\n",
    "        self.n_stacks = n_stacks\n",
    "        self.n_multihead = n_multihead\n",
    "        self.n_dims = n_dims\n",
    "        self.norm_layers = nn.LayerNorm(n_dims)\n",
    "        # n_stacks has n_multiheads each\n",
    "        self.multihead_layers = nn.ModuleList(n_stacks*[nn.ModuleList(n_multihead*[nn.MultiheadAttention(embed_dim=n_dims,\n",
    "                                                                                                         num_heads=n_heads,\n",
    "                                                                                                         dropout=dropout), ]), ])\n",
    "        self.ffn = nn.ModuleList(n_stacks*[FFN(n_dims)])\n",
    "        self.mask = torch.triu(torch.ones(seq_len, seq_len),\n",
    "                               diagonal=1).to(dtype=torch.bool)\n",
    "\n",
    "    def forward(self, input_q, input_k, input_v, encoder_output=None, break_layer=None):\n",
    "        for stack in range(self.n_stacks):\n",
    "            for multihead in range(self.n_multihead):\n",
    "                norm_q = self.norm_layers(input_q)\n",
    "                norm_k = self.norm_layers(input_k)\n",
    "                norm_v = self.norm_layers(input_v)\n",
    "                heads_output, _ = self.multihead_layers[stack][multihead](query=norm_q.permute(1, 0, 2),\n",
    "                                                                          key=norm_k.permute(\n",
    "                                                                              1, 0, 2),\n",
    "                                                                          value=norm_v.permute(\n",
    "                                                                              1, 0, 2),\n",
    "                                                                          attn_mask=self.mask.to(Config.device))\n",
    "                heads_output = heads_output.permute(1, 0, 2)\n",
    "                #assert encoder_output != None and break_layer is not None\n",
    "                if encoder_output != None and multihead == break_layer:\n",
    "                    assert break_layer <= multihead, \" break layer should be less than multihead layers and postive integer\"\n",
    "                    input_k = input_v = encoder_output\n",
    "                    input_q = input_q + heads_output\n",
    "                else:\n",
    "                    input_q = input_q + heads_output\n",
    "                    input_k = input_k + heads_output\n",
    "                    input_v = input_v + heads_output\n",
    "            last_norm = self.norm_layers(heads_output)\n",
    "            ffn_output = self.ffn[stack](last_norm)\n",
    "            ffn_output = ffn_output + heads_output\n",
    "        # after loops = input_q = input_k = input_v\n",
    "        return ffn_output\n",
    "\n",
    "\n",
    "class PlusSAINTModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        # n_encoder,n_detotal_responses,seq_len,max_time=300+1\n",
    "        super(PlusSAINTModule, self).__init__()\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "        self.encoder_layer = StackedNMultiHeadAttention(n_stacks=Config.NUM_DECODER,\n",
    "                                                        n_dims=Config.EMBED_DIMS,\n",
    "                                                        n_heads=Config.DEC_HEADS,\n",
    "                                                        seq_len=Config.MAX_SEQ,\n",
    "                                                        n_multihead=1, dropout=0.0)\n",
    "        self.decoder_layer = StackedNMultiHeadAttention(n_stacks=Config.NUM_ENCODER,\n",
    "                                                        n_dims=Config.EMBED_DIMS,\n",
    "                                                        n_heads=Config.ENC_HEADS,\n",
    "                                                        seq_len=Config.MAX_SEQ,\n",
    "                                                        n_multihead=2, dropout=0.0)\n",
    "        self.encoder_embedding = EncoderEmbedding(n_exercises=Config.TOTAL_EXE,\n",
    "                                                  n_categories=Config.TOTAL_CAT,\n",
    "                                                  n_dims=Config.EMBED_DIMS, seq_len=Config.MAX_SEQ)\n",
    "        self.decoder_embedding = DecoderEmbedding(\n",
    "            n_responses=3, n_dims=Config.EMBED_DIMS, seq_len=Config.MAX_SEQ)\n",
    "        self.elapsed_time = nn.Linear(1, Config.EMBED_DIMS)\n",
    "        self.fc = nn.Linear(Config.EMBED_DIMS, 1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        enc = self.encoder_embedding(\n",
    "            exercises=x[\"input_ids\"], categories=x['input_cat'])\n",
    "        dec = self.decoder_embedding(responses=y)\n",
    "        elapsed_time = x[\"input_rtime\"].unsqueeze(-1).float()\n",
    "        ela_time = self.elapsed_time(elapsed_time)\n",
    "        dec = dec + ela_time\n",
    "        # this encoder\n",
    "        encoder_output = self.encoder_layer(input_k=enc,\n",
    "                                            input_q=enc,\n",
    "                                            input_v=enc)\n",
    "        #this is decoder\n",
    "        decoder_output = self.decoder_layer(input_k=dec,\n",
    "                                            input_q=dec,\n",
    "                                            input_v=dec,\n",
    "                                            encoder_output=encoder_output,\n",
    "                                            break_layer=1)\n",
    "        # fully connected layer\n",
    "        out = self.fc(decoder_output)\n",
    "        return out.squeeze()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def training_step(self, batch, batch_ids):\n",
    "        input, labels = batch\n",
    "        target_mask = (input[\"input_ids\"] != 0)\n",
    "        out = self(input, labels)\n",
    "        loss = self.loss(out.float(), labels.float())\n",
    "        out = torch.masked_select(out, target_mask)\n",
    "        out = torch.sigmoid(out)\n",
    "        labels = torch.masked_select(labels, target_mask)\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "        return {\"loss\": loss, \"outs\": out, \"labels\": labels}\n",
    "\n",
    "    def training_epoch_end(self, training_ouput):\n",
    "        out = np.concatenate([i[\"outs\"].cpu().detach().numpy()\n",
    "                              for i in training_ouput]).reshape(-1)\n",
    "        labels = np.concatenate([i[\"labels\"].cpu().detach().numpy()\n",
    "                                 for i in training_ouput]).reshape(-1)\n",
    "        auc = roc_auc_score(labels, out)\n",
    "        self.print(\"train auc\", auc)\n",
    "        self.log(\"train_auc\", auc)\n",
    "\n",
    "    def validation_step(self, batch, batch_ids):\n",
    "        input, labels = batch\n",
    "        target_mask = (input[\"input_ids\"] != 0)\n",
    "        out = self(input, labels)\n",
    "        loss = self.loss(out.float(), labels.float())\n",
    "        out = torch.masked_select(out, target_mask)\n",
    "        out = torch.sigmoid(out)\n",
    "        labels = torch.masked_select(labels, target_mask)\n",
    "        self.log(\"val_loss\", loss, on_step=True, prog_bar=True)\n",
    "        output = {\"outs\": out, \"labels\": labels}\n",
    "        return {\"val_loss\": loss, \"outs\": out, \"labels\": labels}\n",
    "\n",
    "    def validation_epoch_end(self, validation_ouput):\n",
    "        out = np.concatenate([i[\"outs\"].cpu().detach().numpy()\n",
    "                              for i in validation_ouput]).reshape(-1)\n",
    "        labels = np.concatenate([i[\"labels\"].cpu().detach().numpy()\n",
    "                                 for i in validation_ouput]).reshape(-1)\n",
    "        auc = roc_auc_score(labels, out)\n",
    "        self.print(\"val auc\", auc)\n",
    "        self.log(\"val_auc\", auc)\n",
    "        \n",
    "    def predict_step(self, batch, batch_ids):\n",
    "        total_preds = []\n",
    "        input, labels = batch\n",
    "        preds = self.model()\n",
    "        preds = preds.cpu().detach().numpy()\n",
    "        \n",
    "        return total_preds\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_loader, val_loader = get_dataloaders()\n",
    "    saint_plus = PlusSAINTModule()\n",
    "    trainer = pl.Trainer(gpus=-1, max_epochs=5, progress_bar_refresh_rate=21)\n",
    "    trainer.fit(model=saint_plus,\n",
    "                train_dataloader=train_loader,\n",
    "                val_dataloaders=[val_loader, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(model=saint_plus, dataloaders=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dkt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
